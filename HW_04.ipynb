{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f1b5a3-f011-45b5-b392-cece4795188b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DSCI 617 – Homework 04\n",
    "**Felix Asare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb7fbee-eef9-44bd-a418-a18e380bd695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Libraries (SparkSession, col and expr)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c4ba4f6-9d63-426c-b9c0-e6d275eed9b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Diamond Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e66d37c-6993-4484-a50e-6f1267c0c8f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- carat: double (nullable = true)\n |-- cut: string (nullable = true)\n |-- color: string (nullable = true)\n |-- clarity: string (nullable = true)\n |-- depth: double (nullable = true)\n |-- table: double (nullable = true)\n |-- price: integer (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- z: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Creating a schema for the diamonds data\n",
    "diamonds = (\n",
    "    spark.read\n",
    "    .option('delimiter', '\\t')\n",
    "    .option('header', True)\n",
    "    .schema(\n",
    "        'carat DOUBLE, cut STRING, color STRING, clarity STRING, depth DOUBLE, '\n",
    "        'table DOUBLE, price INTEGER, x DOUBLE, y DOUBLE, z DOUBLE'\n",
    "    )\n",
    "    .csv('/FileStore/tables/diamonds.txt')\n",
    ")\n",
    "\n",
    "diamonds.printSchema()\n",
    "\n",
    "diamonds.createOrReplaceTempView('diamonds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf6e02c-0154-4657-8afd-ecb19df47e26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 1: Grouping By Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa4b1054-922a-4053-8771-974cb20eb3fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "# Create a rank_cut function\n",
    "def rank_cut(cut):\n",
    "    rank_dict = {\n",
    "        'Fair': 1,\n",
    "        'Good': 2,\n",
    "        'Very Good': 3,\n",
    "        'Premium': 4,\n",
    "        'Ideal': 5\n",
    "    }\n",
    "    return rank_dict.get(cut, None)\n",
    "    \n",
    "# register the function as a UDF\n",
    "rank_cut_udf = udf(rank_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bb6fb7f-483c-4504-8238-29c91e4921df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+---------+---------+---------+--------+\n|      cut|n_diamonds|avg_price|avg_carat|avg_depth|avg_table|cut_rank|\n+---------+----------+---------+---------+---------+---------+--------+\n|     Fair|      1610|   4359.0|     1.05|    64.04|    59.05|       1|\n|     Good|      4906|   3929.0|     0.85|    62.37|    58.69|       2|\n|Very Good|     12082|   3982.0|     0.81|    61.82|    57.96|       3|\n|  Premium|     13791|   4584.0|     0.89|    61.26|    58.75|       4|\n|    Ideal|     21551|   3458.0|      0.7|    61.71|    55.95|       5|\n+---------+----------+---------+---------+---------+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "# Group diamonds by cut\n",
    "grouped_cut = spark.sql(\"\"\"\n",
    "    SELECT cut, \n",
    "           COUNT(*) AS n_diamonds, \n",
    "           ROUND(AVG(price), 0) AS avg_price, \n",
    "           ROUND(AVG(carat), 2) AS avg_carat, \n",
    "           ROUND(AVG(depth), 2) AS avg_depth, \n",
    "           ROUND(AVG(table), 2) AS avg_table\n",
    "    FROM diamonds\n",
    "    GROUP BY cut\n",
    "\"\"\").withColumn(\"cut_rank\", rank_cut_udf(col(\"cut\"))).orderBy(\"cut_rank\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "002a5c0e-f4d2-4f22-9b5a-eefa99dc0fde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 2: Filtering based on Carat Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18906ddb-be7f-45c8-b7db-b004cd93d9c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of diamonds in the carat range [0, 1) is 34880\nThe Number of diamonds in the carat range [1, 2) is 16906\nThe Number of diamonds in the carat range [2, 3) is 2114\nThe Number of diamonds in the carat range [3, 4) is 34\nThe Number of diamonds in the carat range [4, 5) is 5\nThe Number of diamonds in the carat range [5, 6) is 1\n"
     ]
    }
   ],
   "source": [
    "# Use a loop to count the number of diamonds\n",
    "bins = ['[0,1)', '[1,2)', '[2,3)', '[3,4)', '[4,5)', '[5,6)']\n",
    "for bin_range in bins:\n",
    "    lower, upper = bin_range.strip('[]').replace(')', '').split(',')\n",
    "    count = diamonds.filter((diamonds.carat >= lower) & (diamonds.carat < upper)).count()\n",
    "    print(f\"The Number of diamonds in the carat range [{lower}, {upper}) is {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b93344f0-56fa-463f-be55-8043b8c9a2f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 3: Binning by Carat Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd052a3c-d71e-4f1f-9887-eb25a551d3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to bin carat\n",
    "def carat_bin(carat):\n",
    "    if 0 <= carat < 1:\n",
    "        return '[0, 1)'\n",
    "    elif 1 <= carat < 2:\n",
    "        return '[1, 2)'\n",
    "    elif 2 <= carat < 3:\n",
    "        return '[2, 3)'\n",
    "    elif 3 <= carat < 4:\n",
    "        return '[3, 4)'\n",
    "    elif 4 <= carat < 5:\n",
    "        return '[4, 5)'\n",
    "    elif 5 <= carat < 6:\n",
    "        return '[5, 6)'\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "# Register the function as a UDF\n",
    "carat_bin_udf = udf(carat_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ef6931-6a6a-4e8d-b177-f3d63ee98a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+---------+\n|carat|      cut|color|clarity|depth|table|price|   x|   y|   z|carat_bin|\n+-----+---------+-----+-------+-----+-----+-----+----+----+----+---------+\n| 0.23|    Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|   [0, 1)|\n| 0.21|  Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|   [0, 1)|\n| 0.23|     Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|   [0, 1)|\n| 0.29|  Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|   [0, 1)|\n| 0.31|     Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|   [0, 1)|\n| 0.24|Very Good|    J|   VVS2| 62.8| 57.0|  336|3.94|3.96|2.48|   [0, 1)|\n| 0.24|Very Good|    I|   VVS1| 62.3| 57.0|  336|3.95|3.98|2.47|   [0, 1)|\n| 0.26|Very Good|    H|    SI1| 61.9| 55.0|  337|4.07|4.11|2.53|   [0, 1)|\n| 0.22|     Fair|    E|    VS2| 65.1| 61.0|  337|3.87|3.78|2.49|   [0, 1)|\n| 0.23|Very Good|    H|    VS1| 59.4| 61.0|  338| 4.0|4.05|2.39|   [0, 1)|\n|  0.3|     Good|    J|    SI1| 64.0| 55.0|  339|4.25|4.28|2.73|   [0, 1)|\n| 0.23|    Ideal|    J|    VS1| 62.8| 56.0|  340|3.93| 3.9|2.46|   [0, 1)|\n| 0.22|  Premium|    F|    SI1| 60.4| 61.0|  342|3.88|3.84|2.33|   [0, 1)|\n| 0.31|    Ideal|    J|    SI2| 62.2| 54.0|  344|4.35|4.37|2.71|   [0, 1)|\n|  0.2|  Premium|    E|    SI2| 60.2| 62.0|  345|3.79|3.75|2.27|   [0, 1)|\n| 0.32|  Premium|    E|     I1| 60.9| 58.0|  345|4.38|4.42|2.68|   [0, 1)|\n|  0.3|    Ideal|    I|    SI2| 62.0| 54.0|  348|4.31|4.34|2.68|   [0, 1)|\n|  0.3|     Good|    J|    SI1| 63.4| 54.0|  351|4.23|4.29| 2.7|   [0, 1)|\n|  0.3|     Good|    J|    SI1| 63.8| 56.0|  351|4.23|4.26|2.71|   [0, 1)|\n|  0.3|Very Good|    J|    SI1| 62.7| 59.0|  351|4.21|4.27|2.66|   [0, 1)|\n+-----+---------+-----+-------+-----+-----+-----+----+----+----+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'carat_bin' to the DataFrame\n",
    "diamonds.withColumn('carat_bin', carat_bin_udf(col('carat'))).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1409e853-45ae-49ef-9c01-33f80f75874f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fca3bd1-81ef-40e9-9d5d-b7d753bc1e67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- imdb_title_id: string (nullable = true)\n |-- title: string (nullable = true)\n |-- year: string (nullable = true)\n |-- genre: string (nullable = true)\n |-- duration: string (nullable = true)\n |-- country: string (nullable = true)\n |-- language: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load movies data\n",
    "movies = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv('/FileStore/tables/imdb/movies.txt')\n",
    "\n",
    "\n",
    "movies.printSchema()\n",
    "\n",
    "movies.createOrReplaceTempView('movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5f1424-b32e-4704-9c16-70afb642bcd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- imdb_name_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- birth_name: string (nullable = true)\n |-- height: string (nullable = true)\n |-- bio: string (nullable = true)\n |-- date_of_birth: string (nullable = true)\n |-- date_of_death: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load names data\n",
    "names = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv('/FileStore/tables/imdb/names.txt')\n",
    "\n",
    "names.printSchema()\n",
    "names.createOrReplaceTempView('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b6c966-2898-4bbe-a017-f739edb0520c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- imdb_title_id: string (nullable = true)\n |-- ordering: string (nullable = true)\n |-- imdb_name_id: string (nullable = true)\n |-- category: string (nullable = true)\n |-- characters: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load title_principals data\n",
    "title_principals = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv('/FileStore/tables/imdb/title_principals-1.txt')\n",
    "\n",
    "title_principals.printSchema()\n",
    "title_principals.createOrReplaceTempView('title_principals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "551ebe13-51af-4d83-8dc7-36330b19f20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- imdb_title_id: string (nullable = true)\n |-- rating: string (nullable = true)\n |-- total_votes: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Load ratings data\n",
    "ratings = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv('/FileStore/tables/imdb/ratings-1.txt')\n",
    "\n",
    "ratings.printSchema()\n",
    "ratings.createOrReplaceTempView('ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580f03dc-e0c9-4992-be63-f6377a6632e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in movies: 85855\nNumber of records in names: 297710\nNumber of records in title_principals: 835513\nNumber of records in ratings: 85855\n"
     ]
    }
   ],
   "source": [
    "# Number os records in movies, names, ratings, title_principals\n",
    "print(f\"Number of records in movies: {movies.count()}\")\n",
    "print(f\"Number of records in names: {names.count()}\")\n",
    "print(f\"Number of records in title_principals: {title_principals.count()}\")\n",
    "print(f\"Number of records in ratings: {ratings.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19c494e-82c7-4ad1-a496-ce933730b8e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 4: Number of Appearances by Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f90b81e-35f9-4260-9ff5-e5673999214b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n|             name|appearances|\n+-----------------+-----------+\n|         Mohanlal|        163|\n| Amitabh Bachchan|        142|\n|        Mammootty|        140|\n|     Eric Roberts|        133|\n|       John Wayne|        132|\n| Gérard Depardieu|        130|\n|      Prakash Raj|        125|\n|     Akshay Kumar|        115|\n|   Michael Madsen|        107|\n|         Andy Lau|        102|\n|Catherine Deneuve|        101|\n|      Anupam Kher|         99|\n|     Brahmanandam|         99|\n|    Michael Caine|         94|\n|       Ajay Devgn|         94|\n|  Christopher Lee|         93|\n+-----------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "result = (\n",
    "    title_principals\n",
    "    .filter((col(\"category\") == \"actor\") | (col(\"category\") == \"actress\"))\n",
    "    .groupBy(\"imdb_name_id\")\n",
    "    .agg(F.count(\"*\").alias(\"appearances\"))\n",
    "    .join(names, \"imdb_name_id\", \"inner\")\n",
    "    .select(\"name\", \"appearances\") \n",
    "    .orderBy(col(\"appearances\").desc()) \n",
    "    .limit(16)\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da43992b-e44a-42e2-ac79-7716497d019e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 5: Average Rating by Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fedc419-57e1-4c58-9420-96e2a7cba7a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+-----------+----------+\n|name                 |num_films|total_votes|avg_rating|\n+---------------------+---------+-----------+----------+\n|Christopher Nolan    |11       |1.1653144E7|8.22      |\n|Lee Unkrich          |5        |3329612.0  |8.14      |\n|Hayao Miyazaki       |12       |2254496.0  |8.01      |\n|Quentin Tarantino    |14       |9460772.0  |7.93      |\n|Sergio Leone         |7        |1720654.0  |7.93      |\n|Stanley Kubrick      |13       |4232356.0  |7.78      |\n|David Fincher        |10       |6944421.0  |7.76      |\n|Sam Mendes           |10       |3067512.0  |7.73      |\n|Alejandro G. Iñárritu|7        |2067540.0  |7.61      |\n|Wes Anderson         |9        |2173090.0  |7.61      |\n|Peter Jackson        |13       |7304418.0  |7.58      |\n|Brad Bird            |6        |2294748.0  |7.57      |\n|Alfonso Cuarón       |8        |2078975.0  |7.54      |\n|Andrew Stanton       |5        |2649551.0  |7.52      |\n|Bong Joon Ho         |8        |1172684.0  |7.51      |\n|Akira Kurosawa       |32       |1061519.0  |7.51      |\n+---------------------+---------+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# #Average director rating\n",
    "from pyspark.sql.functions import col, count, sum, avg, round\n",
    "avg_result = (\n",
    "    title_principals\n",
    "    .filter(col('category') == 'director')\n",
    "    .join(ratings, 'imdb_title_id', 'inner')\n",
    "    .groupBy('imdb_name_id')\n",
    "    .agg(\n",
    "        count('*').alias('num_films'),\n",
    "        sum('total_votes').alias('total_votes'),\n",
    "        round(avg('rating'), 2).alias('avg_rating')\n",
    "    )\n",
    "    .filter(col('total_votes') >= 1000000)\n",
    "    .filter(col('num_films') >= 5)\n",
    "    .join(names, 'imdb_name_id', 'inner')\n",
    "    .select('name', 'num_films', 'total_votes', 'avg_rating')\n",
    "    .orderBy(col('avg_rating').desc())\n",
    "    .limit(16)\n",
    ")\n",
    "\n",
    "avg_result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16fc659f-56ec-4bb9-b256-1796731e7a94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Problem 6: Actors Appearing in Horror Films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "601a70dd-4e3b-47eb-a877-42c453b7980f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9557"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Horror films\n",
    "horror_films = movies.filter(expr('genre LIKE \"%Horror%\"'))\n",
    "horror_films.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0309561e-375d-4aeb-927b-f7b0e53bca69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n|            name|num_films|\n+----------------+---------+\n| Christopher Lee|       56|\n|   Peter Cushing|       47|\n|   Boris Karloff|       46|\n|  John Carradine|       43|\n|     Bela Lugosi|       38|\n|   Vincent Price|       34|\n| Lance Henriksen|       33|\n|    Eric Roberts|       29|\n|  Lon Chaney Jr.|       28|\n|    Bill Moseley|       27|\n|       Tony Todd|       27|\n|     Paul Naschy|       26|\n|Donald Pleasence|       26|\n|       Sergey A.|       23|\n|  Robert Englund|       23|\n|     Brad Dourif|       23|\n+----------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "horror_result = (\n",
    "    title_principals\n",
    "    .filter((col('category') == 'actor') | (col('category') == 'actress'))\n",
    "    .join(horror_films, 'imdb_title_id', 'inner')\n",
    "    .groupBy('imdb_name_id')\n",
    "    .agg(count('imdb_title_id').alias('num_films'))\n",
    "    .join(names, 'imdb_name_id', 'inner')\n",
    "    .select('name', 'num_films')\n",
    "    .orderBy(col('num_films').desc())\n",
    "    .limit(16)\n",
    ")\n",
    "\n",
    "# Display results\n",
    "horror_result.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "HW_04",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}